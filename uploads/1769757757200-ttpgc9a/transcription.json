{
  "id": "1769757757200-ttpgc9a",
  "title": "Kubernetes Community Meeting 20210422",
  "participants": [],
  "createdAt": "2026-01-30T07:26:12.978Z",
  "status": "completed",
  "transcription": {
    "text": "All right, we are officially recording. Welcome to the new monthly Kubernetes Contributor Community Meeting. I think I got that all in the right order. I just want to remind everybody that we do have a code of conduct, so please be aware of that, be excellent to one another, and we will get started. As a courtesy, please do mute when you are not speaking, that way everybody is sure that they can be heard, but you're feel free to unmute if you would like to be part of the discussion. And my name is Laura Santa Maria. I am from LogDNA and I am also part of SIG Contributor Experience. So I'm also the one responsible for this meeting now. And we're trying out a new format, so we'll see how this goes. I don't think we have a note-taker yet. If somebody could take over that, that'd be great. And thank you Bob for dropping that in the Zoom chat. So if somebody could grab the notes, we'll see how much we keep up with. If not, I'll keep up with it, but we'll see. All right, well while somebody is thinking about becoming the note-taker or I will take it, just a couple quick announcements. This is the new updated community meeting format, so afterwards we'd love to hear your thoughts on what you thought about the whole experience. Feel free to reach out to me, laura.santamaria@logdna.com, or you can reach out to us on Slack. You'll be able to find me there. And yeah, that doc's overloaded, so we're going to just keep going and it'll be very entertaining as we go. But that's the only really big announcement that I have in terms of this community meeting. And if you have announcements for next time, please do let me know. A couple notes about release updates. So 1.21.0 was first released earlier this month on April 8th. Congratulations to the release team. The retro was held on April 15th, so that I think was earlier this week or last week. It was last week. I know what day it is, that's perfectly fine. Some patch release updates for you. There is a link to the patch releases doc, but there's some upcoming patches. So 1.18.19 release target is the 28th of April. 1.19.11 cherry-pick deadline of May 7th, release target May 12th. 1.20.7 same cherry-pick deadline and release target as with 1.21.1. And there were some patches released as of April 15th as well as the big release from 1.21.0. And that's 1.18.18, 1.19.10, and 1.20.6. So that's the quick update on the releases. And on that note, now we get to the fun part, which is discussions. And we're going to be starting with the release cadence KEP, which is from our release team. And we have Jeremy here to kind of be my expert because I don't know everything about this KEP no matter how much I read about it. Welcome Jeremy, thank you so much for being with us today. Thanks for having me. I'm excited to talk about this topic, it's near and dear to my heart for the last few weeks. In essence, what this change, you know, KEPs are proposals for changing Kubernetes. They can be changing Kubernetes in terms of code, so it could be like a new feature. We're also using them to propose policy changes. And this one is specifically around the release cadence for Kubernetes. So in 2020, due to the many things that happened in the world, you know, we slowed the 1.19 release down and extended it quite a bit to just give everybody breathing room, just to kind of take space to deal with all the events that were unfolding. What that ended up doing was leaving not enough time to do two more releases in the rest of the year. So we ended up with three releases in 2020. And during that time, there was a lot of discussion in various places. It's hard to pull all the threads together to find all of the comments and all of the discussion that had happened. But going forward we thought that we, SIG Release, proposed kind of adopting that formally. So instead of the four releases that normally would have happened once a quarter, moving to a cadence that's three releases. There's a few, you know, a few reasons that we thought about doing this. One, it's a lot of overhead to build the releases out and maintain the various branches, and this will give us a little bit of breathing room from the release team's perspective. But also from a consumer's perspective, it's really hard to keep up, speaking from previous experience. It's hard to keep up with the number of releases and when things fall out of support you have to try to catch up really quickly. And one of the benefits of the slowdown in 2020 was that people had a little bit more breathing room, things stayed in support for a little bit longer, and we just kind of wanted to formalize that. So really what the KEP at a really high level is proposing is some rough guidance on planning the release calendars. And the guidance kind of breaks down into a few things, three real bullet points. One is that releases should be around 15 weeks. Previously they were much shorter than that, 10, 11, 12 weeks depending on where it fell on the calendar. So this isn't like a great big difference. It's not like 1.19 where it was very, very long. But it does add just enough breathing room I think to move deadlines around a little bit, give people a little bit more time to get things into the release, give it a little bit more time to plan things for the next release as well. The second thing is that it's going to build, bake in a little bit of downtime between each release. From the release team's perspective, one of the things that's great about cycle to cycle is that we onboard a whole bunch of new contributors, some experienced contributors to the release team as shadows to learn the roles and help us staff the release teams going forward. And it's always a challenge to get that done, especially for some of the roles like enhancements that have to hit the ground running. Speaking as a previous enhancements lead, I know like it's really hard to pick the shadows in time to get them really, really engaged because you know, we hit the ground as soon as the release officially kicks off, trying to collect all of the KEPs that are going to make it into the release and make sure the authors are pushing those things forward. So this will give us a little bit more time to do that, but also to plan the, get the schedule firmed up and and not rushed to make sure we get all of the - like right now the 1.22 schedule is being discussed, there's a PR that's open for that. I can, after I'm done talking, I can go grab the link and drop it into the notes. But essentially, you know, there's feedback coming in and when we have less time to get that finalized, it kind of rushes that process. So that's the second bullet point: two weeks of downtime. And then the third thing is that we did this during 2020, and we really did this during the 1.19 release and the 1.20 release, was give time for KubeCon to occur. Generally, KubeCon occurs during one of the releases, probably two of the releases during the year. And it's, you know, in person, it's really, really hard to focus on any of the release team activities. When things are online, it's still difficult, like you're still trying to focus your attention on KubeCon and not having to worry about getting, any of the release team meetings, getting reviews done, no deadlines landing in that week. So the third bullet point of this kind of rough policy is that we're going to block out that week from any activities occurring from the release team's perspective. There won't be any deadlines that week, we won't have release team meetings. We're also going to treat the week before and after kind of as a loose, also kind of blacked out period, but not as formal as that one week period. So with those three things in mind, those three kind of release planning things, in the KEP we've kind of spelled out what 2021 would look like with a three-release cadence and what 2022 would look like with a three-release cadence. And what you end up seeing is that we end up with a release in April, we will end up with a release in August, and we end up with a release in December. So with those three things, it's pretty predictable to know, you know, when this release is going to happen down to a week or two, you know, depending on how things shift within the year. Um, the KEP is currently approved by almost everybody that needs to approve it. We're still waiting for SIG Testing to weigh in, but everybody else has provided such great feedback. We've had a lot of back and forth, a lot of really great intense collaboration to get this to the point where it's ready to go. I would invite everybody to go check it out. But at a high level, three things: 15-week releases, two weeks between releases, no release activities during KubeCon, and that will result in three releases per year. Yeah, um, do you want to also talk about how we're going to - it's a bit TBD - but how we're going to evaluate whether or not this change is successful? Yeah, thanks for - I totally spaced on that one. So what we're going to do is after every release we're going to submit a survey or send a survey out to the community. Um, this is really going to target end users and contributors to get feedback on how this is going, uh, what changes do we need to make to the process going forward. And after we do three of these releases, we're going to take that feedback and make a decision about whether this will become a permanent change or whether we should either revert back to the old way or think of another, do we need to make any other alterations to the process. So for 1.22, 1.23, 1.24 we're going to try to collect that feedback and work through the survey results, which is still TBD. Um, we have a couple of in the KEP issue, there's a couple of related issues to firm that stuff up during the 1.22 time frame. Those surveys will typically go out at the end of the release and then we'll catch up in the subsequent release to process that information and kind of roll it into the next. So then after we collect those three release feedbacks, we will kind of synthesize everything together and then revisit this topic with a public communication via the mailing list, the SIG Release mailing list, and GitHub issues to kind of figure out whether this is going to be a permanent change or whether there are additional changes that need to be made. Thanks for pointing that out Josh. Had it on my paper and totally missed it. Awesome. I'm pretty excited about that. Any questions? Any other things they would love to discuss about it? Comments? I had a question for you Jeremy, if that's all right. Uh, I'm kind of curious just to how we're going about deciding what counts or like what the goal is for a new release and is this exclusive to just the main Kubernetes project or does this also sync up with Kubernetes SIG groups? That is a super good question. And uh, that's another topic that's under a lot of discussion right now. Um, what, you know, typically the releases are really focused on things that are in the Kubernetes/Kubernetes repo. We do track things that are out of the repo, but there's not a great policy or really definition of of what releases look like for things that are outside of KK. Um, when we talk about the release, we're talking mostly about KK. We do track things and sometimes there are blog posts that go out for those other things, but typically the release itself, so 1.21, 1.22 is really building off of things that are in the Kubernetes/Kubernetes repo. What goes into those releases really comes down to what the SIGs want to deliver in that upcoming cycle. Um, the way that a change goes into Kubernetes is through a Kubernetes Enhancement Proposal or a KEP. Uh, authors are responsible for writing those things, the SIGs are responsible for approving and reviewing those things, and then really figuring out what bandwidth do they have to work on these things during the upcoming release. So the the way we've kind of moved toward to collect those things for the release is that SIGs are opting in and telling us, the release team, hey we plan on delivering these things. Um, could be five things, it could be two things, it could be one thing, it could be zero things. Um, when they opt in and say they're going to deliver these features or these, you know, graduate this thing from alpha to beta or beta to stable, each one of those things comes with a certain number of requirements. Uh, it may have to have a PRR production readiness review, it may need to have a feature flag change, it may need to have additional tests or conformance tests delivered for it. And part of what the release team does is once somebody has opted in and said hey we're going to do this thing for the release, the release team's really helping them meet those milestones. So we're looking to say, uh, your KEP isn't fully complete, it has to be in implementable state, it has to have graduation criteria defined, it has to have test plans defined. That's what aligns with something we call enhancements freeze. Then from that point on code has to be done, and that has to be done by the code freeze period of the release. And again these things are enforced for the KK repo. Um, obviously things don't have to land by code freeze because we're not locking down other repos. The code freeze mechanism comes into play for the KK repo. So the release team is again like checking to make sure that all the PRs that are necessary for that work are done, um, making sure that we know about all the PRs that are necessary for that work to be done so we can track it, checking to see if any bugs have been opened, watching CI signal and kind of relating it back to those PRs and just kind of doing the mechanisms of making sure that those things successfully land in the release. But what goes into the release really comes down to the SIG. So if SIG Node wants to land some brand new feature, SIG Node's really responsible for that feature landing. They're responsible for hitting those deadlines, they're responsible for the KEP, um, shepherding it through that process with support from the release team. Does that answer your question? So in that particular scenario if there was anything that the Node SIG group particularly needed from the main codebase, it would be up to them to go in and make sure that that happens for themselves. Yeah. In general, SIGs own code, right? So the SIG Node, SIG Node owns things like the kubelet and they own pieces of the Kubernetes/Kubernetes kind of giant repo that are really specific to SIG Node. Same thing for storage, same thing for API machinery. Um, there are owners files that land in those various places that kind of correspond to the SIGs. And uh, they're responsible for making sure that those things get the proper reviews, that the code gets done. Um, and then I mean there are other reviews that have to happen too, like outside of just node-specific code, there may have to be API reviews that happen. Uh, and those are a different set of people, but they're really responsible for ensuring that those things, those checkboxes get done before the release happens. If those things don't happen by enhancements freeze or by code freeze, we remove them from the release. So the the release team does own some of that, like we have some say over what gets in and we have some mechanisms for kind of clawing things back, but it's a shared responsibility with a lot of responsibility landing on the SIGs. I see. Awesome. Yeah, I'm pretty new to the whole project so I appreciate the thoroughness. Yeah, no worries. Awesome. Any other questions or comments about the release cadence KEP? If you're not comfortable unmuting, you're more than welcome to drop the note in the Zoom chat and I will read it out for you. All right. Well, you can still ask more questions in the Zoom chat, but we'll move on to our next topic. Thank you so much Jeremy for all that information. I'm sure a lot of people will find that very interesting on the recording too. Next up we have the kubectl exit code overhaul with SIG CLI. And I believe I have someone from SIG CLI on the call to kind of talk up, and that's Ricardo, right? Yeah. Hello. Good afternoon. That's afternoon here. Hey folks. So yeah, Laura, can I share my screen just a bit? Just thanks Josh. You should be good. Thanks. So I'm gonna share my screen just because Josh asked me to show some codes, but I will not show. And I will try to keep in my five minutes. Yeah, so we are trying to normalize the code from kubectl and the best way I think to show you the problem is actually showing the problem. So the first one is a plugin that I wrote that exits with the exit code whatever I put, right? So if I put, and I don't know what is the actually the exit code from kubectl, right? The second one is one that we got from kubectl diff which returns to us an error code of one, but by main pages from diff, one is if it's different, two is if in trouble, but we didn't had this before, like it was returning one for everything. And we have a bunch of of error codes that show us actually they don't show nothing to us like if I try to create a cluster role and it validates on the client side I have a return code of one or if I try to create an invalid namespace and I get an error code of one as well or maybe if I get some access denied let me show you I promise that's quick. Yeah so if I do this inside I get an exit code one. So I guess I've shown you what's what's the point here, right? The point that we get here is anything that you run inside kubectl you you get an error code which doesn't doesn't symbolize or doesn't represent what what actually happened. You don't know if the error code is is from the client side or from the server side or even if it's from an external command like from diff. You cannot delegate that for diff or for a plugin. If a plugin wants to exit wants to return a different exit code other than one to represent things, we just we just don't know it. It it it can't use the the error code from from the plugin and and simulate that something correctly occurred but it doesn't. Right so the main points of attention that we want actually the first one it's hard to pragmatically distinguish errors from kubectl commands. We don't know what error happened right. We don't know where this error happened, if the error happened in the client side or or if it happened in the server side or even if it was a subprogram different error code. And what we want with this KEP is to document the possible kubectl exit codes so the same way that we have in other Unix programs that says oh if you got this error code it it symbolizes this thing or if you got this other error code it symbolizes the other thing right. And also to allow to delegate to the subcommands like diff and plugins to have their own exit codes but this doesn't this this should not impact in the error code from kubectl. And we want to gradually implement the exit code standardization for each command. So we still need to resolve how we are going to do that because we can't standardize at once but or we can do that gradually but this this might get some impacts for the user. And why are we bringing this here? Because we have two possible caveats at least right. So the first one is we cannot use well-known exit codes. I will put the the notes that I'm reading here because I am like there are some links here. And the other one and the mostly notable is CIs or users that already relies on the behavior of kubectl nowadays right. So if they behaves on the exit code one and we say oh see now we are going to say that if an error occurs in the server side we are going to use the error code 65 to 70. We are going to define those those exit code ranges so this might impact in some CI/CD or even in users relying into this in scripts. And we have some unresolved needs and things that needs attention so how how is this behavior going to happen with Windows users? I I really don't know about that so probably we should ping folks using kubectl in Windows and how to deal with pod specific exit code when using kubectl run or kubectl exec. And this is something that we are we are still discussing. I already put I I also put in the notes some code navigation if someone wants to know how the commands they they happen inside kubectl with the complete validate and run. It's a pretty nice and what how the error they are delegated but I think the the most important thing here is that we need the feedback from the community because this this might be a breaking change for a lot of CI/CD providers or for people relying on on different exit codes. So please folks I I really love answering comments that just just help us doing that. Okay and I guess that's all. I don't know if Maciej or Eddie they want to say something else. No, I think Ricardo presented the topic very well. Uh, what I probably have to add is have a look at the KEP. I linked the KEP Ricardo also linked in the notes that he put together. Um, before we start actually writing something, we would love to get as much feedback as possible since this will be a bigger change that will be with us for probably for the remaining time of the kubectl lifetime, um, and we don't expect to break that after this happens. The actual implementation should be pretty straightforward. It is the initial discussion and the feedback that we want gather about the shape of the proposal is critical, um, to kick it off. So we won't be definitely rushing with this. Uh, we will we will just leave it for open for at least this and the next release and then eventually we will be uh trying to come up with this uh initially hidden behind a feature flag and uh if there will be no objections we will be uh slowly shipping this towards all of the users. Awesome. Thank you everybody. Anybody have any questions, comments, concerns, things you'd like to just say right away? I mentioned this in chat, but um, if you do want to reach out to some end users, we can engage directly with the CNCF end user group and direct them to provide feedback to the KEP. Uh, we've done that before, mostly for surveys. Um, so I don't know if you want to just have them comment directly on the KEP or potentially have um like a feedback survey or something like that. But either way we can send something out to them. Okay, yeah, we'll try to figure something. Uh, I think that people, the end users might not necessarily be interested in reading the KEP, um, so maybe some kind of a survey would be probably the easiest for them to digest. Yeah, thanks Bob. One of the things I want to make sure we hit is like CI/CD practitioners and there's a bunch of different like users that this will impact in some place. So that's a great idea. The there's also the CNCF maintainer list, which has like Argo or the like CD groups which has Argo, Jenkins X and a lot of those providers, so can boost the visibility through that. I I can send to them if you think that's good Bob. I just I just need the mailing list address and I can join, send and wait for some feedback as well. I can get you that later. Thanks. So one of my other questions here is going to be um what plans do we have for user outreach? Because I actually see a lot more potential for breakage, you know, with people's personal bash scripts, um, than necessarily with actual um project plumbing. I think this could be weaved into the larger discussion around how do we talk about changes in the project during the release process. Um, it sounds like something that would be feasible to have as a pre-release bloggy thing, um, as well as noted in uh in the release notes and um I guess the the all of the release train communication that we do once the release actually goes out. Yeah, I think we need to engage the um you know contributor, well this isn't really contributor marketing although they'd probably have some ideas because like one of the questions I have up in the air that I really have no I don't know, you know central dilemma is is it better to have a large message saying hey here's the things we're about to break in this release which would actually be nice to have in general versus um giving out messages for specific issues because always my worry about a roundup um message is that people won't read the whole thing and then they'll miss the issue that really applies to them. So I so we were yeah we were actually discussing some of this in SIG Release recently. Um, I think that as part of the as part of any KEP um that may I think it's I think it's worthwhile to um more visibly note when a KEP involves a deprecation. Um, and I think as part of that there could be an addition to the release team checklist that says like hey is your thing a deprecation, here are some additional things that you should do um to make sure that it's it's visibly noted for people who might be consuming this uh this enhancement. Um, so that doesn't exist today, but I agree that the for the talking about wide scale changes, um, some folks mentioned contributor marketing, I think it's important that the SIG, SIG Docs, SIG Release, and contributor marketing are involved in whatever that communication plan is. I mean for this particular change and I I think that could easily um apply to similar broader changes is promoting the change, uh discussing about it and making sure that it is not on by default. So you need to explicitly set some I don't know, flag environment variable, something to opt in, provide the feedback and in the early stages speak up about it and you know at the early stage we will be open about oh yeah it will change but you can already provide feedback from something working because from my personal experience I know that there are people more willing to provide feedback when they could give it a try rather than uh theorize on problems. One of the things that I had in mind too was is there any sort of mailing list or circle for people who provide managed Kubernetes as a service like the cloud providers or some of the other SAS companies? Because that's a great way to get folks that ask their customers directly. The CNCF has a list. Cool. All right. So we did this reboot with only 30 minutes on the clock. Uh, so we are at time. Um, but I know some people privately want to keep talking, so I don't think we can we can stop if folks want to keep talking about different topics. We're welcome to stay on. Uh, I do want to just take a quick note or two for the folks who do need to hop off. There are like 4.5 pages of shoutouts that I'm not going to read out like I normally would at the end of a community meeting. Please do go check those and we will read them out at the next community meeting. But shoutout to just everybody. Thanks all for coming. We really appreciate you joining us for this new experiment of the community meeting being more of a discussion format. And again if you have any feedback on that you're welcome to reach out. And folks can stay on and keep talking. But I want to make sure I got that in there for folks who have to jump off. I have a quick one before we stop the recording. Uh, so just to back up on the upcoming patch schedule what we were discussing within by having one additional 1.18 release um was to line it up with the uh the current patch the upcoming patches. Um, so the release date for I apparently can't edit the the working doc, but the release date for 1.18.19, the cherry-pick deadline is May 7th and the release target will be May 12th. Awesome, thank you for that correction and it looks like somebody did get in there and correct it before the doc went in and out again so I think we're good. I think so. Yay. There is actually a question in the chat about changes in normalization around errors originating from kubelet via CRI or CNI. I don't know if that's a new topic. No, no really a question, it was more of a just a point of order if we start doing normalization I'd be interested. We we can certainly help out in the container runtimes to make these error messages easier to consume. Um, we do we put a lot of useful information in our logs but you're not going to get all that back in the error message. Sometimes the error message received is the final error message and and it it may not make any sense. Um, for example if you're doing a some kind of a pull image or run you may not get the error you would get if you read the entire logs: 'well we tried over here, we tried over there,' um, you know sometimes one error doesn't really explain the whole thing. So just adds up, we we can help at the CRI level. Um, I might I might suggest uh including that as a a note to both SIG Node and SIG Network mailing lists um just to get that conversation started. I'm not sure that enough people who are over those areas are on this call right now. Yeah, I was surprised to find this call today. I was like whoops wasn't in my calendar. Yeah we had a little bit of an issue with the uh Google Calendar. So short version is we're quite large as a group and apparently that causes some problems for our community calendar. So we're going to be working on that eventually um but that hopefully might explain why it appeared and then disappeared and then there were emails. So I apologize on that one. Um, which which emails? Because I want to make sure I get that into the notes. It was SIG Networking and what was the other one? SIG Node. Thank you. Um, and Dims may have additional suggestions. I say it might be worth just sending one out to K-Dev. Yeah there's already a thread in K-Dev for the CLI exit code so the um just add to that. Cool. Okay. Somebody had raised his hand here but then he disappeared from Zoom, so well hopefully they'll come back. But on that note I think we're kind of hitting the end of the conversation today. So again thank you so much for sticking around a little bit longer than the original invite that disappeared that reappeared that disappeared actually had on the calendar. I hope you all found something very interesting but thank you all for coming. I hope this was useful and we will see you next month. Take care folks. Thank you. Bye.",
    "segments": [
      {
        "speaker": "Laura Santa Maria",
        "text": "All right, we are officially recording. Welcome to the new monthly Kubernetes Contributor Community Meeting. I think I got that all in the right order. I just want to remind everybody that we do have a code of conduct, so please be aware of that, be excellent to one another, and we will get started. As a courtesy, please do mute when you are not speaking, that way everybody is sure that they can be heard, but you're feel free to unmute if you would like to be part of the discussion. And my name is Laura Santa Maria. I am from LogDNA and I am also part of SIG Contributor Experience. So I'm also the one responsible for this meeting now. And we're trying out a new format, so we'll see how this goes. I don't think we have a note-taker yet. If somebody could take over that, that'd be great. And thank you Bob for dropping that in the Zoom chat. So if somebody could grab the notes, we'll see how much we keep up with. If not, I'll keep up with it, but we'll see. All right, well while somebody is thinking about becoming the note-taker or I will take it, just a couple quick announcements. This is the new updated community meeting format, so afterwards we'd love to hear your thoughts on what you thought about the whole experience. Feel free to reach out to me, laura.santamaria@logdna.com, or you can reach out to us on Slack. You'll be able to find me there. And yeah, that doc's overloaded, so we're going to just keep going and it'll be very entertaining as we go. But that's the only really big announcement that I have in terms of this community meeting. And if you have announcements for next time, please do let me know. A couple notes about release updates. So 1.21.0 was first released earlier this month on April 8th. Congratulations to the release team. The retro was held on April 15th, so that I think was earlier this week or last week. It was last week. I know what day it is, that's perfectly fine. Some patch release updates for you. There is a link to the patch releases doc, but there's some upcoming patches. So 1.18.19 release target is the 28th of April. 1.19.11 cherry-pick deadline of May 7th, release target May 12th. 1.20.7 same cherry-pick deadline and release target as with 1.21.1. And there were some patches released as of April 15th as well as the big release from 1.21.0. And that's 1.18.18, 1.19.10, and 1.20.6. So that's the quick update on the releases. And on that note, now we get to the fun part, which is discussions. And we're going to be starting with the release cadence KEP, which is from our release team. And we have Jeremy here to kind of be my expert because I don't know everything about this KEP no matter how much I read about it. Welcome Jeremy, thank you so much for being with us today.",
        "startTime": 0,
        "endTime": 128
      },
      {
        "speaker": "Jeremy",
        "text": "Thanks for having me. I'm excited to talk about this topic, it's near and dear to my heart for the last few weeks. In essence, what this change, you know, KEPs are proposals for changing Kubernetes. They can be changing Kubernetes in terms of code, so it could be like a new feature. We're also using them to propose policy changes. And this one is specifically around the release cadence for Kubernetes. So in 2020, due to the many things that happened in the world, you know, we slowed the 1.19 release down and extended it quite a bit to just give everybody breathing room, just to kind of take space to deal with all the events that were unfolding. What that ended up doing was leaving not enough time to do two more releases in the rest of the year. So we ended up with three releases in 2020. And during that time, there was a lot of discussion in various places. It's hard to pull all the threads together to find all of the comments and all of the discussion that had happened. But going forward we thought that we, SIG Release, proposed kind of adopting that formally. So instead of the four releases that normally would have happened once a quarter, moving to a cadence that's three releases. There's a few, you know, a few reasons that we thought about doing this. One, it's a lot of overhead to build the releases out and maintain the various branches, and this will give us a little bit of breathing room from the release team's perspective. But also from a consumer's perspective, it's really hard to keep up, speaking from previous experience. It's hard to keep up with the number of releases and when things fall out of support you have to try to catch up really quickly. And one of the benefits of the slowdown in 2020 was that people had a little bit more breathing room, things stayed in support for a little bit longer, and we just kind of wanted to formalize that. So really what the KEP at a really high level is proposing is some rough guidance on planning the release calendars. And the guidance kind of breaks down into a few things, three real bullet points. One is that releases should be around 15 weeks. Previously they were much shorter than that, 10, 11, 12 weeks depending on where it fell on the calendar. So this isn't like a great big difference. It's not like 1.19 where it was very, very long. But it does add just enough breathing room I think to move deadlines around a little bit, give people a little bit more time to get things into the release, give it a little bit more time to plan things for the next release as well. The second thing is that it's going to build, bake in a little bit of downtime between each release. From the release team's perspective, one of the things that's great about cycle to cycle is that we onboard a whole bunch of new contributors, some experienced contributors to the release team as shadows to learn the roles and help us staff the release teams going forward. And it's always a challenge to get that done, especially for some of the roles like enhancements that have to hit the ground running. Speaking as a previous enhancements lead, I know like it's really hard to pick the shadows in time to get them really, really engaged because you know, we hit the ground as soon as the release officially kicks off, trying to collect all of the KEPs that are going to make it into the release and make sure the authors are pushing those things forward. So this will give us a little bit more time to do that, but also to plan the, get the schedule firmed up and and not rushed to make sure we get all of the - like right now the 1.22 schedule is being discussed, there's a PR that's open for that. I can, after I'm done talking, I can go grab the link and drop it into the notes. But essentially, you know, there's feedback coming in and when we have less time to get that finalized, it kind i rushes that process. So that's the second bullet point: two weeks of downtime. And then the third thing is that we did this during 2020, and we really did this during the 1.19 release and the 1.20 release, was give time for KubeCon to occur. Generally, KubeCon occurs during one of the releases, probably two of the releases during the year. And it's, you know, in person, it's really, really hard to focus on any of the release team activities. When things are online, it's still difficult, like you're still trying to focus your attention on KubeCon and not having to worry about getting, any of the release team meetings, getting reviews done, no deadlines landing in that week. So the third bullet point of this kind i rough policy is that we're going to block out that week from any activities occurring from the release team's perspective. There won't be any deadlines that week, we won't have release team meetings. We're also going to treat the week before and after kind i as a loose, also kind i blacked out period, but not as formal as that one week period. So with those three things in mind, those three kind i release planning things, in the KEP we've kind i spelled out what 2021 would look like with a three-release cadence and what 2022 would look like with a three-release cadence. And what you end up seeing is that we end up with a release in April, we will end up with a release in August, and we end up with a release in December. So with those three things, it's pretty predictable to know, you know, when this release is going to happen down to a week or two, you know, depending on how things shift within the year. Um, the KEP is currently approved by almost everybody that needs to approve it. We're still waiting for SIG Testing to weigh in, but everybody else has provided such great feedback. We've had a lot of back and forth, a lot of really great intense collaboration to get this to the point where it's ready to go. I would invite everybody to go check it out. But at a high level, three things: 15-week releases, two weeks between releases, no release activities during KubeCon, and that will result in three releases per year.",
        "startTime": 128,
        "endTime": 286
      },
      {
        "speaker": "Josh",
        "text": "Yeah, um, do you want to also talk about how we're going to - it's a bit TBD - but how we're going to evaluate whether or not this change is successful?",
        "startTime": 286,
        "endTime": 294
      },
      {
        "speaker": "Jeremy",
        "text": "Yeah, thanks for - I totally spaced on that one. So what we're going to do is after every release we're going to submit a survey or send a survey out to the community. Um, this is really going to target end users and contributors to get feedback on how this is going, uh, what changes do we need to make to the process going forward. And after we do three of these releases, we're going to take that feedback and make a decision about whether this will become a permanent change or whether we should either revert back to the old way or think of another, do we need to make any other alterations to the process. So for 1.22, 1.23, 1.24 we're going to try to collect that feedback and work through the survey results, which is still TBD. Um, we have a couple of in the KEP issue, there's a couple of related issues to firm that stuff up during the 1.22 time frame. Those surveys will typically go out at the end of the release and then we'll catch up in the subsequent release to process that information and kind i roll it into the next. So then after we collect those three release feedbacks, we will kind i synthesize everything together and then revisit this topic with a public communication via the mailing list, the SIG Release mailing list, and GitHub issues to kind i figure out whether this is going to be a permanent change or whether there are additional changes that need to be made. Thanks for pointing that out Josh. Had it on my paper and totally missed it.",
        "startTime": 294,
        "endTime": 374
      },
      {
        "speaker": "Laura Santa Maria",
        "text": "Awesome. I'm pretty excited about that. Any questions? Any other things they would love to discuss about it? Comments?",
        "startTime": 374,
        "endTime": 396
      },
      {
        "speaker": "Josh",
        "text": "I had a question for you Jeremy, if that's all right. Uh, I'm kind i curious just to how we're going about deciding what counts or like what the goal is for a new release and is this exclusive to just the main Kubernetes project or does this also sync up with Kubernetes SIG groups?",
        "startTime": 396,
        "endTime": 412
      },
      {
        "speaker": "Jeremy",
        "text": "That is a super good question. And uh, that's another topic that's under a lot of discussion right now. Um, what, you know, typically the releases are really focused on things that are in the Kubernetes/Kubernetes repo. We do track things that are out of the repo, but there's not a great policy or really definition of of what releases look like for things that are outside of KK. Um, when we talk about the release, we're talking mostly about KK. We do track things and sometimes there are blog posts that go out for those other things, but typically the release itself, so 1.21, 1.22 is really building off of things that are in the Kubernetes/Kubernetes repo. What goes into those releases really comes down to what the SIGs want to deliver in that upcoming cycle. Um, the way that a change goes into Kubernetes is through a Kubernetes Enhancement Proposal or a KEP. Uh, authors are responsible for writing those things, the SIGs are responsible for approving and reviewing those things, and then really figuring out what bandwidth do they have to work on these things during the upcoming release. So the the way we've kind i moved toward to collect those things for the release is that SIGs are opting in and telling us, the release team, hey we plan on delivering these things. Um, could be five things, it could be two things, it could be one thing, it could be zero things. Um, when they opt in and say they're going to deliver these features or these, you know, graduate this thing from alpha to beta or beta to stable, each one of those things comes with a certain number of requirements. Uh, it may have to have a PRR production readiness review, it may need to have a feature flag change, it may need to have additional tests or conformance tests delivered for it. And part of what the release team does is once somebody has opted in and said hey we're going to do this thing for the release, the release team's really helping them meet those milestones. So we're looking to say, uh, your KEP isn't fully complete, it has to be in implementable state, it has to have graduation criteria defined, it has to have test plans defined. That's what aligns with something we call enhancements freeze. Then from that point on code has to be done, and that has to be done by the code freeze period of the release. And again these things are enforced for the KK repo. Um, obviously things don't have to land by code freeze because we're not locking down other repos. The code freeze mechanism comes into play for the KK repo. So the release team is again like checking to make sure that all the PRs that are necessary for that work are done, um, making sure that we know about all the PRs that are necessary for that work to be done so we can track it, checking to see if any bugs have been opened, watching CI signal and kind i relating it back to those PRs and just kind i doing the mechanisms of making sure that those things successfully land in the release. But what goes into the release really comes down to the SIG. So if SIG Node wants to land some brand new feature, SIG Node's really responsible for that feature landing. They're responsible for hitting those deadlines, they're responsible for the KEP, um, shepherding it through that process with support from the release team. Does that answer your question?",
        "startTime": 412,
        "endTime": 540
      },
      {
        "speaker": "Josh",
        "text": "So in that particular scenario if there was anything that the Node SIG group particularly needed from the main codebase, it would be up to them to go in and make sure that that happens for themselves.",
        "startTime": 540,
        "endTime": 553
      },
      {
        "speaker": "Jeremy",
        "text": "Yeah. In general, SIGs own code, right? So the SIG Node, SIG Node owns things like the kubelet and they own pieces of the Kubernetes/Kubernetes kind i giant repo that are really specific to SIG Node. Same thing for storage, same thing for API machinery. Um, there are owners files that land in those various places that kind i correspond to the SIGs. And uh, they're responsible for making sure that those things get the proper reviews, that the code gets done. Um, and then I mean there are other reviews that have to happen too, like outside of just node-specific code, there may have to be API reviews that happen. Uh, and those are a different set of people, but they're really responsible for ensuring that those things, those checkboxes get done before the release happens. If those things don't happen by enhancements freeze or by code freeze, we remove them from the release. So the the release team does own some of that, like we have some say over what gets in and we have some mechanisms for kind i clawing things back, but it's a shared responsibility with a lot of responsibility landing on the SIGs.",
        "startTime": 553,
        "endTime": 613
      },
      {
        "speaker": "Josh",
        "text": "I see. Awesome. Yeah, I'm pretty new to the whole project so I appreciate the thoroughness. Yeah, no worries.",
        "startTime": 613,
        "endTime": 614
      },
      {
        "speaker": "Laura Santa Maria",
        "text": "Awesome. Any other questions or comments about the release cadence KEP? If you're not comfortable unmuting, you're more than welcome to drop the note in the Zoom chat and I will read it out for you. All right. Well, you can still ask more questions in the Zoom chat, but we'll move on to our next topic. Thank you so much Jeremy for all that information. I'm sure a lot of people will find that very interesting on the recording too. Next up we have the kubectl exit code overhaul with SIG CLI. And I believe I have someone from SIG CLI on the call to kind i talk up, and that's Ricardo, right?",
        "startTime": 614,
        "endTime": 687
      },
      {
        "speaker": "Ricardo Katz",
        "text": "Yeah. Hello. Good afternoon. That's afternoon here. Hey folks. So yeah, Laura, can I share my screen just a bit? Just thanks Josh. You should be good. Thanks. So I'm gonna share my screen just because Josh asked me to show some codes, but I will not show. And I will try to keep in my five minutes. Yeah, so we are trying to normalize the code from kubectl and the best way I think to show you the problem is actually showing the problem. So the first one is a plugin that I wrote that exits with the exit code whatever I put, right? So if I put, and I don't know what is the actually the exit code from kubectl, right? The second one is one that we got from kubectl diff which returns to us an error code of one, but by main pages from diff, one is if it's different, two is if in trouble, but we didn't had this before, like it was returning one for everything. And we have a bunch of of error codes that show us actually they don't show nothing to us like if I try to create a cluster role and it validates on the client side I have a return code of one or if I try to create an invalid namespace and I get an error code of one as well or maybe if I get some access denied let me show you I promise that's quick. Yeah so if I do this inside I get an exit code one. So I guess I've shown you what's what's the point here, right? The point that we get here is anything that you run inside kubectl you you get an error code which doesn't doesn't symbolize or doesn't represent what what actually happened. You don't know if the error code is is from the client side or from the server side or even if it's from an external command like from diff. You cannot delegate that for diff or for a plugin. If a plugin wants to exit wants to return a different exit code other than one to represent things, we just we just don't know it. It it it can't use the the error code from from the plugin and and simulate that something correctly occurred but it doesn't. Right so the main points of attention that we want actually the first one it's hard to pragmatically distinguish errors from kubectl commands. We don't know what error happened right. We don't know where this error happened, if the error happened in the client side or or if it happened in the server side or even if it was a subprogram different error code. And what we want with this KEP is to document the possible kubectl exit codes so the same way that we have in other Unix programs that says oh if you got this error code it it symbolizes this thing or if you got this other error code it symbolizes the other thing right. And also to allow to delegate to the subcommands like diff and plugins to have their own exit codes but this doesn't this this should not impact in the error code from kubectl. And we want to gradually implement the exit code standardization for each command. So we still need to resolve how we are going to do that because we can't standardize at once but or we can do that gradually but this this might get some impacts for the user. And why are we bringing this here? Because we have two possible caveats at least right. So the first one is we cannot use well-known exit codes. I will put the the notes that I'm reading here because I am like there are some links here. And the other one and the mostly notable is CIs or users that already relies on the behavior of kubectl nowadays right. So if they behaves on the exit code one and we say oh see now we are going to say that if an error occurs in the server side we are going to use the error code 65 to 70. We are going to define those those exit code ranges so this might impact in some CI/CD or even in users relying into this in scripts. And we have some unresolved needs and things that needs attention so how how is this behavior going to happen with Windows users? I I really don't know about that so probably we should ping folks using kubectl in Windows and how to deal with pod specific exit code when using kubectl run or kubectl exec. And this is something that we are we are still discussing. I already put I I also put in the notes some code navigation if someone wants to know how the commands they they happen inside kubectl with the complete validate and run. It's a pretty nice and what how the error they are delegated but I think the the most important thing here is that we need the feedback from the community because this this might be a breaking change for a lot of CI/CD providers or for people relying on on different exit codes. So please folks I I really love answering comments that just just help us doing that. Okay and I guess that's all. I don't know if Maciej or Eddie they want to say something else.",
        "startTime": 687,
        "endTime": 984
      },
      {
        "speaker": "Maciej Szulik",
        "text": "No, I think Ricardo presented the topic very well. Uh, what I probably have to add is have a look at the KEP. I linked the KEP Ricardo also linked in the notes that he put together. Um, before we start actually writing something, we would love to get as much feedback as possible since this will be a bigger change that will be with us for probably for the remaining time of the kubectl lifetime, um, and we don't expect to break that after this happens. The actual implementation should be pretty straightforward. It is the initial discussion and the feedback that we want gather about the shape of the proposal is critical, um, to kick it off. So we won't be definitely rushing with this. Uh, we will we will just leave it for open for at least this and the next release and then eventually we will be uh trying to come up with this uh initially hidden behind a feature flag and uh if there will be no objections we will be uh slowly shipping this towards all of the users.",
        "startTime": 985,
        "endTime": 1011
      },
      {
        "speaker": "Laura Santa Maria",
        "text": "Awesome. Thank you everybody. Anybody have any questions, comments, concerns, things you'd like to just say right away?",
        "startTime": 1011,
        "endTime": 1025
      },
      {
        "speaker": "Bob",
        "text": "I mentioned this in chat, but um, if you do want to reach out to some end users, we can engage directly with the CNCF end user group and direct them to provide feedback to the KEP. Uh, we've done that before, mostly for surveys. Um, so I don't know if you want to just have them comment directly on the KEP or potentially have um like a feedback survey or something like that. But either way we can send something out to them.",
        "startTime": 1026,
        "endTime": 1052
      },
      {
        "speaker": "Maciej Szulik",
        "text": "Okay, yeah, we'll try to figure something. Uh, I think that people, the end users might not necessarily be interested in reading the KEP, um, so maybe some kind i a survey would be probably the easiest for them to digest.",
        "startTime": 1053,
        "endTime": 1067
      },
      {
        "speaker": "Josh",
        "text": "Yeah, thanks Bob. One of the things I want to make sure we hit is like CI/CD practitioners and there's a bunch of different like users that this will impact in some place. So that's a great idea. The there's also the CNCF maintainer list, which has like Argo or the like CD groups which has Argo, Jenkins X and a lot of those providers, so can boost the visibility through that.",
        "startTime": 1067,
        "endTime": 1084
      },
      {
        "speaker": "Ricardo Katz",
        "text": "I I can send to them if you think that's good Bob. I just I just need the mailing list address and I can join, send and wait for some feedback as well.",
        "startTime": 1084,
        "endTime": 1099
      },
      {
        "speaker": "Josh",
        "text": "I can get you that later. Thanks. So one of my other questions here is going to be um what plans do we have for user outreach? Because I actually see a lot more potential for breakage, you know, with people's personal bash scripts, um, than necessarily with actual um project plumbing.",
        "startTime": 1099,
        "endTime": 1131
      },
      {
        "speaker": "Laura Santa Maria",
        "text": "I think this could be weaved into the larger discussion around how do we talk about changes in the project during the release process. Um, it sounds like something that would be feasible to have as a pre-release bloggy thing, um, as well as noted in uh in the release notes and um I guess the the all of the release train communication that we do once the release actually goes out.",
        "startTime": 1132,
        "endTime": 1166
      },
      {
        "speaker": "Josh",
        "text": "Yeah, I think we need to engage the um you know contributor, well this isn't really contributor marketing although they'd probably have some ideas because like one of the questions I have up in the air that I really have no I don't know, you know central dilemma is is it better to have a large message saying hey here's the things we're about to break in this release which would actually be nice to have in general versus um giving out messages for specific issues because always my worry about a roundup um message is that people won't read the whole thing and then they'll miss the issue that really applies to them. So I so we were yeah we were actually discussing some of this in SIG Release recently. Um, I think that as part of the as part of any KEP um that may I think it's I think it's worthwhile to um more visibly note when a KEP involves a deprecation. Um, and I think as part of that there could be an addition to the release team checklist that says like hey is your thing a deprecation, here are some additional things that you should do um to make sure that it's it's visibly noted for people who might be consuming this uh this enhancement. Um, so that doesn't exist today, but I agree that the for the talking about wide scale changes, um, some folks mentioned contributor marketing, I think it's important that the SIG, SIG Docs, SIG Release, and contributor marketing are involved in whatever that communication plan is. I mean for this particular change and I I think that could easily um apply to similar broader changes is promoting the change, uh discussing about it and making sure that it is not on by default. So you need to explicitly set some I don't know, flag environment variable, something to opt in, provide the feedback and in the early stages speak up about it and you know at the early stage we will be open about oh yeah it will change but you can already provide feedback from something working because from my personal experience I know that there are people more willing to provide feedback when they could give it a try rather than uh theorize on problems.",
        "startTime": 1166,
        "endTime": 1209
      },
      {
        "speaker": "Eddie Zaneski",
        "text": "One of the things that I had in mind too was is there any sort of mailing list or circle for people who provide managed Kubernetes as a service like the cloud providers or some of the other SAS companies? Because that's a great way to get folks that ask their customers directly.",
        "startTime": 1210,
        "endTime": 1213
      },
      {
        "speaker": "Bob",
        "text": "The CNCF has a list. Cool.",
        "startTime": 1214,
        "endTime": 1214
      },
      {
        "speaker": "Laura Santa Maria",
        "text": "All right. So we did this reboot with only 30 minutes on the clock. Uh, so we are at time. Um, but I know some people privately want to keep talking, so I don't think we can we can stop if folks want to keep talking about different topics. We're welcome to stay on. Uh, I do want to just take a quick note or two for the folks who do need to hop off. There are like 4.5 pages of shoutouts that I'm not going to read out like I normally would at the end of a community meeting. Please do go check those and we will read them out at the next community meeting. But shoutout to just everybody. Thanks all for coming. We really appreciate you joining us for this new experiment of the community meeting being more of a discussion format. And again if you have any feedback on that you're welcome to reach out. And folks can stay on and keep talking. But I want to make sure I got that in there for folks who have to jump off.",
        "startTime": 1214,
        "endTime": 1270
      },
      {
        "speaker": "Laura Santa Maria",
        "text": "I have a quick one before we stop the recording. Uh, so just to back up on the upcoming patch schedule what we were discussing within by having one additional 1.18 release um was to line it up with the uh the current patch the upcoming patches. Um, so the release date for I apparently can't edit the the working doc, but the release date for 1.18.19, the cherry-pick deadline is May 7th and the release target will be May 12th.",
        "startTime": 1270,
        "endTime": 1298
      },
      {
        "speaker": "Bob",
        "text": "There is actually a question in the chat about changes in normalization around errors originating from kubelet via CRI or CNI. I don't know if that's a new topic.",
        "startTime": 1299,
        "endTime": 1312
      },
      {
        "speaker": "Jeremy",
        "text": "No, no really a question, it was more of a just a point of order if we start doing normalization I'd be interested. We we can certainly help out in the container runtimes to make these error messages easier to consume. Um, we do we put a lot of useful information in our logs but you're not going to get all that back in the error message. Sometimes the error message received is the final error message and and it it may not make any sense. Um, for example if you're doing a some kind i a pull image or run you may not get the error you would get if you read the entire logs: 'well we tried over here, we tried over there,' um, you know sometimes one error doesn't really explain the whole thing. So just adds up, we we can help at the CRI level.",
        "startTime": 1312,
        "endTime": 1338
      },
      {
        "speaker": "Laura Santa Maria",
        "text": "Um, I might I might suggest uh including that as a a note to both SIG Node and SIG Network mailing lists um just to get that conversation started. I'm not sure that enough people who are over those areas are on this call right now.",
        "startTime": 1338,
        "endTime": 1358
      },
      {
        "speaker": "Jeremy",
        "text": "Yeah, I was surprised to find this call today. I was like whoops wasn't in my calendar.",
        "startTime": 1358,
        "endTime": 1374
      },
      {
        "speaker": "Laura Santa Maria",
        "text": "Yeah we had a little bit of an issue with the uh Google Calendar. So short version is we're quite large as a group and apparently that causes some problems for our community calendar. So we're going to be working on that eventually um but that hopefully might explain why it appeared and then disappeared and then there were emails. So I apologize on that one. Um, which which emails? Because I want to make sure I get that into the notes. It was SIG Networking and what was the other one? SIG Node. Thank you. Um, and Dims may have additional suggestions. I say it might be worth just sending one out to K-Dev. Yeah there's already a thread in K-Dev for the CLI exit code so the um just add to that. Cool. Okay. Somebody had raised his hand here but then he disappeared from Zoom, so well hopefully they'll come back. But on that note I think we're kind i hitting the end of the conversation today. So again thank you so much for sticking around a little bit longer than the original invite that disappeared that reappeared that disappeared actually had on the calendar. I hope you all found something very interesting but thank you all for coming. I hope this was useful and we will see you next month. Take care folks. Thank you. Bye.",
        "startTime": 1374,
        "endTime": 1417
      }
    ],
    "speakers": [
      "Laura Santa Maria",
      "Jeremy",
      "Josh",
      "Ricardo Katz",
      "Maciej Szulik",
      "Bob",
      "Eddie Zaneski"
    ],
    "duration": 0,
    "language": "en"
  },
  "audioPath": "uploads/1769757757200-ttpgc9a/audio.mp3"
}